# ğŸ“‹ Live Detection System - Code Changes Summary

## Overview of Implementation

This document outlines the changes made to enable live animal detection with video storage in MongoDB Atlas using your trained `best.pt` YOLOv8 model.

## ğŸ”„ System Flow

```
Camera Feed (Webcam/CCTV)
    â†“
[YOLOv8 Inference] â† best.pt model
    â†“
[Filter: Keep Animals, Drop Humans]
    â†“
[Print Terminal Alert: "ALERT: tiger - Confidence: 0.87"]
    â†“
[BufferFrames: Keep last 30 frames (3 seconds)]
    â†“
[On Animal Detection]
    â”œâ†’ Capture video clip from buffer (MP4)
    â”œâ†’ POST to Backend with Video + Metadata
    â”‚
    â””â†’ Backend Processing:
        â”œâ†’ Upload video to Cloudinary (secure URL)
        â”œâ†’ Save detection record to MongoDB Atlas
        â”‚   â””â†’ Detection { cctvId, timestamp, objects[], videoUrl }
        â””â†’ Return HTTP 201 (Created)
```

## ğŸ“ Files Modified/Created

### 1. **Backend: Detection Model** âœï¸
**File:** `backend/src/model/Detection.js`

**Change:** Added `videoUrl` field to store Cloudinary video link
```javascript
videoUrl: {
    type: String,
    default: null,
},
```

### 2. **Backend: Detection Controller** âœï¸
**File:** `backend/src/controller/detectionController.js`

**Changes:**
- Added Cloudinary import to upload videos
- Modified `createDetection()` to:
  - Accept multipart/form-data with optional video file
  - Parse stringified JSON fields (from form data)
  - Upload video to Cloudinary if provided
  - Store video URL in detection record
  
**Key Logic:**
```javascript
// If file provided, upload to Cloudinary
if (req.file && req.file.buffer) {
    const uploadResult = await cloudinary.uploader.upload(tmpPath, { 
        resource_type: 'video', 
        folder: 'detections' 
    });
    videoUrl = uploadResult.secure_url;
}
```

### 3. **Backend: Detection Routes** âœï¸
**File:** `backend/src/route/detectionRoute.js`

**Change:** Added upload middleware to accept video files
```javascript
detectionRouter.post("/", upload.single('video'), createDetection);
```

Now accepts:
- **JSON POST:** JSON detections without video (old format)
- **Multipart POST:** Form data with video file attachment (new format)

---

## ğŸ¤– ML Service: Core Detection

### 4. **Python: Main App Service** âœï¸
**File:** `backend/ml-service/app.py`

**Changes:**
- Added frame buffer (deque) to keep last 30 frames
- Added human filtering logic
- Added terminal alert logging
- Modified `send_detection_to_backend()` to:
  - Accept optional `video_path` parameter
  - Send as multipart/form-data when video present
  - Send as JSON when video absent
- Added video clip creation in `process_cctv_stream()`

**Key Addition:**
```python
# filter humans - only alert for animals
animal_detections = [d for d in detections.get('objects', []) 
                     if d.get('class_name', '').lower() not in ('human', 'humans')]

if animal_detections:
    # print terminal alerts
    for d in animal_detections:
        logger.warning(f"ALERT: {d.get('class_name')} - Confidence: {d.get('confidence'):.2f}")
```

### 5. **Python: Live Detection Script** ğŸ†•
**File:** `backend/ml-service/live_detection.py`

**New complete script for live camera detection:**

**Class:** `LiveAnimalDetector`
- Loads trained YOLOv8 model
- Connects to webcam/CCTV
- Runs real-time inference
- Filters animals only (excludes humans)
- Captures video clips
- Sends alerts to backend

**Key Methods:**
- `detect_from_camera()` - Main detection loop
- `is_animal_detection()` - Filter humans
- `capture_clip()` - Create MP4 from frame buffer
- `send_alert_to_backend()` - POST alert with video

**Features:**
- âœ… Prints alerts to terminal: "ALERT: tiger - Confidence: 0.87"
- âœ… Captures 3-second video clips (30 frames)
- âœ… Sends multipart request with video + metadata
- âœ… Cooldown period (10 sec) to avoid spam
- âœ… Command-line arguments for customization

### 6. **Python: Integration Tests** ğŸ†•
**File:** `backend/ml-service/test_integration.py`

**Test Suite:**
- âœ… Model file exists
- âœ… YOLOv8 loads correctly
- âœ… Has required animal classes
- âœ… Backend server health
- âœ… Detection endpoint responsive
- âœ… Cloudinary configured
- âœ… MongoDB URI set
- âœ… Live detection script available

Run: `python test_integration.py`

---

## ğŸ“š Documentation Created

### 7. **Guide: Live Detection Setup** ğŸ†•
**File:** `backend/ml-service/LIVE_DETECTION_GUIDE.md`

Complete guide including:
- Architecture overview
- Step-by-step setup
- How to run live detection
- Database schema examples
- Troubleshooting guide
- Advanced usage

### 8. **Quick Start Guide** ğŸ†•
**File:** `backend/ml-service/QUICKSTART.md`

5-minute setup guide with:
- Prerequisites checklist
- Quick setup steps
- Verification tests
- Expected output examples
- Common troubleshooting

---

## ğŸ”‘ Key Features Implemented

### âœ‚ï¸ Human Filtering
```python
ANIMAL_CLASSES = {'porcupine', 'redfox', 'hyena', 'tiger'}

# Only alerts for animals, ignores humans
if class_name.lower() not in ANIMAL_CLASSES:
    continue  # Skip humans
```

### ğŸ”” Terminal Alerts
```
2026-02-26 14:35:30 - [WARNING] - ğŸš¨ ALERT: tiger detected - Confidence: 0.87
2026-02-26 14:35:31 - [WARNING] - ğŸš¨ ALERT: hyena detected - Confidence: 0.72
```

### ğŸ“¹ Video Clip Capture (3 seconds)
- Maintains deque of 30 frames (3 sec at 10 FPS)
- On animal detection, creates MP4 from buffer
- Frame rate: 10 FPS (smooth playback)
- Resolution: 640x480 (lightweight)

### ğŸ“¤ Backend Integration
```python
# Multipart request with video file
files = {'video': open(video_path, 'rb')}
data = {
    'cctv_id': 'cctv_001',
    'timestamp': '2026-02-26T14:35:30.000Z',
    'detections': '[{"className": "tiger", "confidence": 0.87, ...}]',
    'total_detections': '1'
}
requests.post('http://localhost:3000/api/detections', files=files, data=data)
```

### ğŸ’¾ Database Storage
**MongoDB Atlas Detection Record:**
```javascript
{
  cctvId: ObjectId("..."),
  detectionTimestamp: ISODate("2026-02-26T14:35:30Z"),
  objects: [
    {
      classId: 4,
      className: "tiger",
      confidence: 0.87,
      bbox: { xMin: 100, yMin: 100, xMax: 200, yMax: 200 }
    }
  ],
  totalDetections: 1,
  severity: "high",
  videoUrl: "https://res.cloudinary.com/.../detection_video.mp4",  // â† NEW
  alertSent: true,
  processed: false,
  createdAt: ISODate("2026-02-26T14:35:30Z")
}
```

---

## ğŸš€ How to Use

### Step 1: Place Your Model
```bash
copy best.pt d:\3rd year\AniResQ Final\AniResQ\backend\ml-service\models\best.pt
```

### Step 2: Install Dependencies
```bash
cd backend/ml-service
pip install -r requirements.txt
```

### Step 3: Start Backend
```bash
cd backend
npm start
# Waits for: âœ… Server running on http://localhost:3000
```

### Step 4: Run Live Detection
```bash
cd backend/ml-service
python live_detection.py --cctv-id cctv_001 --camera 0 --duration 60
```

### Step 5: Watch Terminal Output
```
ğŸ¥ Starting live detection from camera 0
ğŸ“Œ CCTV ID: cctv_001
ğŸ¯ Filtering for: porcupine, redfox, hyena, tiger
âœ… Camera opened: 1280x720 @ 30.0 FPS
...
ğŸš¨ ALERT: tiger detected - Confidence: 0.87
ğŸ“¤ Capturing clip and sending alert...
âœ… Alert sent to backend (status: 201)
```

---

## ğŸ” Detection Class Filtering

**Your Model Classes:** porcupine, redfox, hyena, **humans**, tiger

**Filtering Logic:**
```python
# In live_detection.py, line ~29
self.animal_classes = {'porcupine', 'redfox', 'hyena', 'tiger'}

# In app.py, line ~240
animal_detections = [d for d in detections.get('objects', []) 
                     if d.get('class_name', '').lower() in self.animal_classes]
```

**Result:**
- âœ… porcupine detected â†’ ALERT âœ…
- âœ… redfox detected â†’ ALERT âœ…
- âœ… hyena detected â†’ ALERT âœ…
- âœ… tiger detected â†’ ALERT âœ…
- âŒ human detected â†’ IGNORED âŒ

---

## ğŸ“Š API Endpoints Modified

### POST `/api/detections` (Modified)
**Old Behavior:** JSON only, no video storage

**New Behavior:** Accepts both:
1. **JSON POST:** `Content-Type: application/json`
   - Direct detection data (no video)
   
2. **Multipart POST:** `Content-Type: multipart/form-data`
   - Form fields: cctv_id, timestamp, detections, total_detections, frame_shape
   - File field: video (MP4)
   - Automatically uploads video to Cloudinary
   - Stores videoUrl in MongoDB

---

## âš™ï¸ Configuration Files

### `.env` (ML Service)
```env
MODEL_PATH=./models/best.pt
BACKEND_URL=http://localhost:3000
CONFIDENCE_THRESHOLD=0.5
CLIP_FRAMES=30
TMPDIR=C:\Temp
```

### `.env` (Backend)
```env
CLOUDINARY_CLOUD_NAME=your_name
CLOUDINARY_API_KEY=your_key
CLOUDINARY_API_SECRET=your_secret
MONGODB_URI=mongodb+srv://user:pass@cluster.mongodb.net/anireq
```

---

## ğŸ§ª Testing

Run integration tests:
```bash
python test_integration.py
```

Expected output:
```
âœ… PASS: Model file exists
âœ… PASS: YOLOv8 model loads
âœ… PASS: Animal classes present
âœ… PASS: Backend server health
âœ… PASS: Detection endpoint responsive
âœ… PASS: Cloudinary configured
âœ… PASS: MongoDB URI configured
âœ… PASS: Live detection script available

ğŸ“Š RESULTS: 8 passed, 0 failed
âœ… All tests passed! System ready for live detection.
```

---

## ğŸ“ˆ Performance Characteristics

| Component | Time | Notes |
|-----------|------|-------|
| Model load | 4-6 sec | One-time at startup |
| Frame inference | 50-100 ms | Per frame, depends on GPU |
| Video capture | <1 sec | Create clip from buffer |
| Upload to back | 2-5 sec | Multipart POST + file upload |
| Cloudinary store | 1-3 sec | Async, separate from API |
| MongoDB insert | <1 sec | Direct database write |

---

## ğŸ”— Integration Points

### Frontend â†’ Backend
- REST API `/api/detections` (POST)
- Optional: WebSocket for real-time alerts

### Backend â†’ ML Service
- HTTP POST to `/api/detections`
- Sends detection JSON + optional video file

### Backend â†’ Cloudinary
- Upload video file via SDK
- Returns secure URL

### Backend â†’ MongoDB
- Insert Detection document
- Reference video URL

---

## ğŸ’¡ Design Decisions

1. **Frame Buffer vs Disk Caching**
   - âœ… In-memory deque: Fast, low storage, simple
   - âŒ Would be: Disk I/O slower

2. **MP4 Format for Clips**
   - âœ… MP4: Universal, streaming-friendly, good compression
   - âŒ Alternatives: AVI too large, WebM less compatible

3. **Cloudinary for Storage**
   - âœ… Managed: No server size limits, CDN delivery
   - âŒ Direct MongoDB: 16MB document limit, slower

4. **10 FPS Clip Playback**
   - âœ… 10 FPS: 30 frames = 3 sec, smooth enough
   - âŒ 30 FPS: 90 frames = 3 sec, large file size

5. **Human Filtering at ML Service**
   - âœ… Early: Reduces unnecessary API calls
   - âŒ Late: Would waste resources

---

## âœ… Verification Checklist

Before running:
- [ ] Model file: `backend/ml-service/models/best.pt` exists
- [ ] Backend configured: Cloudinary, MongoDB
- [ ] Dependencies: `pip install -r requirements.txt` done
- [ ] Backend running: `http://localhost:3000` accessible
- [ ] Webcam: Connected and not in use
- [ ] Drive space: Temp folder has free space

---

## ğŸ“ Support

**Issue:** No detections despite animals present
- Lower confidence: `--confidence 0.3`
- Check model is trained on these classes

**Issue:** Can't connect to backend
- Verify running: `curl http://localhost:3000/health`
- Check port 3000 availability

**Issue:** Video not saving to MongoDB
- Check Cloudinary credentials
- Verify MONGODB_URI in backend `.env`
- Check MongoDB Atlas network access settings

---

## ğŸ¯ Success Metrics

Your implementation is complete when:
1. âœ… Model loads: "âœ… Model loaded! Classes: [...]"
2. âœ… Camera opens: "âœ… Camera opened: 1280x720 @ 30.0 FPS"
3. âœ… Detection works: "ğŸš¨ ALERT: tiger - Confidence: 0.87" appears
4. âœ… Video captured: "âœ… Clip created: ..." message
5. âœ… Backend receives: "âœ… Alert sent to backend (status: 201)"
6. âœ… MongoDB stored: Detection record visible in Atlas with videoUrl

Once all 6 checkmarks pass, your live detection system is **fully operational**! ğŸ‰

---

**Version:** 1.0
**Last Updated:** 2026-02-26
**Status:** Ready for Production Testing
