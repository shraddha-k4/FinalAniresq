# ğŸš€ Quick Start: Live Animal Detection Testing

Follow these steps to test the live detection system with your trained `best.pt` model.

## ğŸ“‹ Prerequisites

- Python 3.8+
- Webcam/Camera connected to your machine
- Backend server running on `http://localhost:3000`
- MongoDB Atlas connection configured
- Cloudinary configured for video uploads

## âš¡ 5-Minute Setup

### Step 1: Copy Your Model
```bash
# Place your trained best.pt in:
d:\3rd year\AniResQ Final\AniResQ\backend\ml-service\models\best.pt
```

### Step 2: Install Dependencies
```bash
cd "d:\3rd year\AniResQ Final\AniResQ\backend\ml-service"
pip install -r requirements.txt
```

### Step 3: Start Backend Server
```bash
# In a separate terminal
cd "d:\3rd year\AniResQ Final\AniResQ\backend"
npm install
npm start
```

Wait for: **"âœ… AniResQ Backend Server running on http://localhost:3000"**

### Step 4: Run Live Detection
```bash
cd "d:\3rd year\AniResQ Final\AniResQ\backend\ml-service"
python live_detection.py --cctv-id cctv_001 --camera 0 --duration 60
```

## ğŸ§ª Verification Tests

Run the integration test suite:
```bash
python test_integration.py
```

**Expected output:**
```
âœ… PASS: Model file exists
âœ… PASS: YOLOv8 model loads
âœ… PASS: Animal classes present
âœ… PASS: Backend server health
âœ… PASS: Detection endpoint responsive
âœ… PASS: Cloudinary configured
âœ… PASS: MongoDB URI configured
âœ… PASS: Live detection script available

ğŸ“Š RESULTS: 8 passed, 0 failed
âœ… All tests passed! System ready for live detection.
```

## ğŸ¥ Live Detection Output

When an animal is detected, you'll see in the terminal:

```
2026-02-26 14:35:22 - [INFO] - ğŸ“¦ Loading model from: ./models/best.pt
2026-02-26 14:35:28 - [INFO] - âœ… Model loaded! Classes: ['porcupine', 'redfox', 'hyena', 'humans', 'tiger']
2026-02-26 14:35:28 - [INFO] - ğŸ¥ Starting live detection from camera 0
2026-02-26 14:35:28 - [INFO] - ğŸ¯ Filtering for: porcupine, redfox, hyena, tiger
2026-02-26 14:35:28 - [INFO] - âœ… Camera opened: 1280x720 @ 30.0 FPS
========================================================================

2026-02-26 14:35:30 - [WARNING] - ğŸš¨ ALERT: tiger detected - Confidence: 0.87
2026-02-26 14:35:31 - [INFO] - ğŸ“¤ Capturing clip and sending alert...
2026-02-26 14:35:31 - [INFO] - âœ… Clip created: C:\Temp\detection_cctv_001_1708953331.mp4 (30 frames)
2026-02-26 14:35:32 - [INFO] - âœ… Alert sent to backend (status: 201)

2026-02-26 14:35:45 - [WARNING] - ğŸš¨ ALERT: hyena detected - Confidence: 0.72
2026-02-26 14:35:46 - [INFO] - ğŸ“¤ Capturing clip and sending alert...
2026-02-26 14:35:46 - [INFO] - âœ… Clip created: C:\Temp\detection_cctv_001_1708953334.mp4 (30 frames)
2026-02-26 14:35:47 - [INFO] - âœ… Alert sent to backend (status: 201)
```

## ğŸ“Š What Happens Behind the Scenes

1. **Model Loading** (4-6 seconds)
   - YOLOv8 model (`best.pt`) loads into memory
   - Classes verified: porcupine, redfox, hyena, tiger, humans

2. **Camera Connection**
   - Opens default webcam (camera index 0)
   - Reads frames at native FPS (typically 30 FPS)
   - Buffers last 30 frames (3 seconds at 10 FPS)

3. **Inference** (Every 5 frames to reduce load)
   - Resizes frame to 640x480
   - Runs YOLOv8 detection at 0.5 confidence threshold
   - Returns class name, confidence, bounding box

4. **Human Filtering** âœ‚ï¸
   - Detections are filtered to exclude "humans" and "humans" class
   - Only animal detections trigger alerts

5. **Alert Generation** ğŸš¨
   - Terminal prints: Class name + confidence score
   - Example: "ALERT: tiger - Confidence: 0.87"
   - Cooldown: 10 seconds per animal class (prevents spam)

6. **Video Capture** ğŸ“¹
   - Captures last 30 frames from buffer
   - Encodes as MP4 video (3 seconds @ 10 FPS)
   - Saves to temp directory

7. **Backend Upload** ğŸ“¤
   - POSTs to `http://localhost:3000/api/detections`
   - Sends multipart/form-data with:
     - Video file attachment
     - Detection metadata (class, confidence, timestamp)
   - Status: HTTP 201 Created

8. **Database Storage** ğŸ’¾
   - Video uploaded to Cloudinary (returns secure URL)
   - Detection record saved to MongoDB Atlas with:
     - CCTV ID
     - Timestamp
     - Animal detections
     - Video URL
     - Severity level

## ğŸ”§ Common Parameters

```bash
# Run for 5 minutes with lower confidence (more detections)
python live_detection.py --camera 0 --confidence 0.3 --duration 300

# Use specific model file
python live_detection.py --model "./models/my_trained_model.pt"

# Connect to remote backend
python live_detection.py --backend "http://192.168.1.100:3000"

# Multiple cameras (if available)
python live_detection.py --camera 0  # Laptop camera
python live_detection.py --camera 1  # External USB camera
```

## ğŸ› ï¸ Troubleshooting

### "Module not found: ultralytics"
```bash
pip install ultralytics torch torchvision
```

### "Cannot open camera 0"
```bash
# Try different camera index
python live_detection.py --camera 1

# Windows: Check Settings â†’ Privacy â†’ Camera
```

### "Connection refused: http://localhost:3000"
```bash
# Verify backend is running
curl http://localhost:3000/health

# If not running, start it:
cd backend && npm start
```

### "Model not found: ./models/best.pt"
```bash
# Check path exists
dir "d:\3rd year\AniResQ Final\AniResQ\backend\ml-service\models\"

# Copy model if missing:
copy "C:\path\to\your\best.pt" "d:\3rd year\AniResQ Final\AniResQ\backend\ml-service\models\best.pt"
```

### No alerts even with animals
```bash
# Lower confidence threshold
python live_detection.py --confidence 0.3

# Verify model classes match your animals
python -c "from ultralytics import YOLO; m = YOLO('./models/best.pt'); print(m.names)"
```

## ğŸ“ˆ Performance Notes

| Setting | FPS | Memory | Accuracy |
|---------|-----|--------|----------|
| Confidence 0.95 | âš¡ High | Low | Few detections |
| Confidence 0.5 | âœ“ Balanced | Balanced | Good |
| Confidence 0.3 | ğŸ¢ Lower | High | More detections |

**Recommendation:** Start with `--confidence 0.5` for best balance.

## ğŸ“š Full Documentation

See [LIVE_DETECTION_GUIDE.md](LIVE_DETECTION_GUIDE.md) for complete documentation including:
- Architecture diagram
- Database schema
- API endpoints
- Advanced usage
- Support & troubleshooting

## âœ… Checklist Before Running

- [ ] `best.pt` model exists in `models/` folder
- [ ] Backend server running: `http://localhost:3000`
- [ ] MongoDB Atlas connection configured
- [ ] Cloudinary credentials in backend `.env`
- [ ] Webcam is accessible
- [ ] Python 3.8+ with dependencies installed
- [ ] No other app is using the camera

## ğŸ¯ Success Criteria

After running, you should see:

1. âœ… Model loads in 4-6 seconds
2. âœ… Camera opens and shows dimensions
3. âœ… Frames are processed (every 5 frames)
4. âœ… When animal appears: Terminal alert with class + confidence
5. âœ… Video clip captured and sent to backend
6. âœ… Backend returns HTTP 201 (Created)
7. âœ… Detection appears in MongoDB Atlas

Once all checkmarks pass, your live detection system is working! ğŸ‰

---

**Next:** Check MongoDB Atlas to see recorded detections with video URLs.
